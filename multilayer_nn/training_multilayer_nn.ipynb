{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m670.2/670.2 MB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:12\u001B[0m\r\n",
      "\u001B[?25hCollecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.8/10.8 MB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.1.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (23.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (4.43.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (10.0.1)\r\n",
      "Collecting triton==2.1.0\r\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.2/89.2 MB\u001B[0m \u001B[31m1.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0mm00:03\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: networkx in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: fsspec in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (2023.9.2)\r\n",
      "Requirement already satisfied: typing-extensions in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (4.8.0)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m801.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:26\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (3.12.4)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\r\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\r\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\r\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\r\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\r\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "Requirement already satisfied: sympy in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Collecting nvidia-nccl-cu12==2.18.1\r\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\r\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\r\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m1.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:08\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Collecting nvidia-nvjitlink-cu12\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.2/20.2 MB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hCollecting joblib>=1.1.1\r\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m302.2/302.2 kB\u001B[0m \u001B[31m1.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting scipy>=1.5.0\r\n",
      "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m36.4/36.4 MB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting threadpoolctl>=2.0.0\r\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Installing collected packages: triton, threadpoolctl, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, joblib, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\r\n",
      "Successfully installed joblib-1.3.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.2.140 nvidia-nvtx-cu12-12.1.105 scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0 torch-2.1.0 triton-2.1.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: numpy in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (1.26.0)\r\n",
      "Requirement already satisfied: pandas in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (2.1.1)\r\n",
      "Requirement already satisfied: matplotlib in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (3.8.0)\r\n",
      "Requirement already satisfied: torch in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (10.0.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (4.43.1)\r\n",
      "Requirement already satisfied: fsspec in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (2023.9.2)\r\n",
      "Requirement already satisfied: triton==2.1.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (2.1.0)\r\n",
      "Requirement already satisfied: networkx in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: jinja2 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: sympy in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: filelock in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (3.12.4)\r\n",
      "Requirement already satisfied: typing-extensions in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from torch) (4.8.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:01.772959144Z",
     "start_time": "2023-10-14T12:34:59.131506285Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         x1        x2  class label\n0  0.781306  1.062984            0\n1 -1.060524 -1.095550            0\n2  0.632125  0.674028            0\n3 -1.424712  0.535203            1\n4  1.383161  1.368510            0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>class label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.781306</td>\n      <td>1.062984</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.060524</td>\n      <td>-1.095550</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.632125</td>\n      <td>0.674028</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.424712</td>\n      <td>0.535203</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.383161</td>\n      <td>1.368510</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"xor.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:01.827215476Z",
     "start_time": "2023-10-14T12:35:01.773765193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X = df[[\"x1\", \"x2\"]].values\n",
    "y = df[\"class label\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:01.829654535Z",
     "start_time": "2023-10-14T12:35:01.826340202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:02.341760377Z",
     "start_time": "2023-10-14T12:35:01.829879995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=True, stratify=y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:02.350317215Z",
     "start_time": "2023-10-14T12:35:02.342413926Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (573, 2)\n",
      "Validation size (64, 2)\n",
      "Test size (113, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size {X_train.shape}\")\n",
    "print(f\"Validation size {X_val.shape}\")\n",
    "print(f\"Test size {X_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:02.393041667Z",
     "start_time": "2023-10-14T12:35:02.389805605Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    X_train[y_train == 0, 0],\n",
    "    X_train[y_train == 0, 1],\n",
    "    marker=\"D\",\n",
    "    markersize=10,\n",
    "    linestyle=\"\",\n",
    "    label=\"Class 0\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    X_train[y_train == 1, 0],\n",
    "    X_train[y_train == 1, 1],\n",
    "    marker=\"^\",\n",
    "    markersize=13,\n",
    "    linestyle=\"\",\n",
    "    label=\"Class 1\",\n",
    ")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-5, 5])\n",
    "\n",
    "plt.xlabel(\"Feature $x_1$\", fontsize=12)\n",
    "plt.ylabel(\"Feature $x_2$\", fontsize=12)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:03.357563483Z",
     "start_time": "2023-10-14T12:35:02.390097879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class PyTorchMLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.all_layers = torch.nn.Sequential(\n",
    "\n",
    "            # first hidden layer\n",
    "            torch.nn.Linear(num_features, 25),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # second hidden layer\n",
    "            torch.nn.Linear(25, 15),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output layer\n",
    "            torch.nn.Linear(15, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.all_layers(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:05.159307615Z",
     "start_time": "2023-10-14T12:35:03.367304749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "\n",
    "train_ds = MyDataset(X_train, y_train)\n",
    "val_ds = MyDataset(X_val, y_val)\n",
    "test_ds = MyDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:05.175344759Z",
     "start_time": "2023-10-14T12:35:05.165299708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            logits = model(features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:05.179721804Z",
     "start_time": "2023-10-14T12:35:05.173947644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 / 010 | Batch 000 / 018 | Train/Val loss: 0.687770\n",
      "Epoch: 001 / 010 | Batch 001 / 018 | Train/Val loss: 0.673314\n",
      "Epoch: 001 / 010 | Batch 002 / 018 | Train/Val loss: 0.690216\n",
      "Epoch: 001 / 010 | Batch 003 / 018 | Train/Val loss: 0.674187\n",
      "Epoch: 001 / 010 | Batch 004 / 018 | Train/Val loss: 0.658506\n",
      "Epoch: 001 / 010 | Batch 005 / 018 | Train/Val loss: 0.674150\n",
      "Epoch: 001 / 010 | Batch 006 / 018 | Train/Val loss: 0.652452\n",
      "Epoch: 001 / 010 | Batch 007 / 018 | Train/Val loss: 0.682071\n",
      "Epoch: 001 / 010 | Batch 008 / 018 | Train/Val loss: 0.670620\n",
      "Epoch: 001 / 010 | Batch 009 / 018 | Train/Val loss: 0.674305\n",
      "Epoch: 001 / 010 | Batch 010 / 018 | Train/Val loss: 0.668361\n",
      "Epoch: 001 / 010 | Batch 011 / 018 | Train/Val loss: 0.666243\n",
      "Epoch: 001 / 010 | Batch 012 / 018 | Train/Val loss: 0.667774\n",
      "Epoch: 001 / 010 | Batch 013 / 018 | Train/Val loss: 0.660209\n",
      "Epoch: 001 / 010 | Batch 014 / 018 | Train/Val loss: 0.655131\n",
      "Epoch: 001 / 010 | Batch 015 / 018 | Train/Val loss: 0.670250\n",
      "Epoch: 001 / 010 | Batch 016 / 018 | Train/Val loss: 0.668859\n",
      "Epoch: 001 / 010 | Batch 017 / 018 | Train/Val loss: 0.661687\n",
      "Train accuracy: 0.7225130796432495 | Val accuracy: 0.65625\n",
      "Epoch: 002 / 010 | Batch 000 / 018 | Train/Val loss: 0.647981\n",
      "Epoch: 002 / 010 | Batch 001 / 018 | Train/Val loss: 0.662855\n",
      "Epoch: 002 / 010 | Batch 002 / 018 | Train/Val loss: 0.638548\n",
      "Epoch: 002 / 010 | Batch 003 / 018 | Train/Val loss: 0.656284\n",
      "Epoch: 002 / 010 | Batch 004 / 018 | Train/Val loss: 0.662187\n",
      "Epoch: 002 / 010 | Batch 005 / 018 | Train/Val loss: 0.649334\n",
      "Epoch: 002 / 010 | Batch 006 / 018 | Train/Val loss: 0.640519\n",
      "Epoch: 002 / 010 | Batch 007 / 018 | Train/Val loss: 0.642840\n",
      "Epoch: 002 / 010 | Batch 008 / 018 | Train/Val loss: 0.650089\n",
      "Epoch: 002 / 010 | Batch 009 / 018 | Train/Val loss: 0.651269\n",
      "Epoch: 002 / 010 | Batch 010 / 018 | Train/Val loss: 0.635857\n",
      "Epoch: 002 / 010 | Batch 011 / 018 | Train/Val loss: 0.624334\n",
      "Epoch: 002 / 010 | Batch 012 / 018 | Train/Val loss: 0.648386\n",
      "Epoch: 002 / 010 | Batch 013 / 018 | Train/Val loss: 0.660128\n",
      "Epoch: 002 / 010 | Batch 014 / 018 | Train/Val loss: 0.652671\n",
      "Epoch: 002 / 010 | Batch 015 / 018 | Train/Val loss: 0.636729\n",
      "Epoch: 002 / 010 | Batch 016 / 018 | Train/Val loss: 0.643354\n",
      "Epoch: 002 / 010 | Batch 017 / 018 | Train/Val loss: 0.638711\n",
      "Train accuracy: 0.8935427665710449 | Val accuracy: 0.859375\n",
      "Epoch: 003 / 010 | Batch 000 / 018 | Train/Val loss: 0.650253\n",
      "Epoch: 003 / 010 | Batch 001 / 018 | Train/Val loss: 0.630321\n",
      "Epoch: 003 / 010 | Batch 002 / 018 | Train/Val loss: 0.632874\n",
      "Epoch: 003 / 010 | Batch 003 / 018 | Train/Val loss: 0.627764\n",
      "Epoch: 003 / 010 | Batch 004 / 018 | Train/Val loss: 0.623807\n",
      "Epoch: 003 / 010 | Batch 005 / 018 | Train/Val loss: 0.625752\n",
      "Epoch: 003 / 010 | Batch 006 / 018 | Train/Val loss: 0.619116\n",
      "Epoch: 003 / 010 | Batch 007 / 018 | Train/Val loss: 0.618372\n",
      "Epoch: 003 / 010 | Batch 008 / 018 | Train/Val loss: 0.611606\n",
      "Epoch: 003 / 010 | Batch 009 / 018 | Train/Val loss: 0.618743\n",
      "Epoch: 003 / 010 | Batch 010 / 018 | Train/Val loss: 0.611878\n",
      "Epoch: 003 / 010 | Batch 011 / 018 | Train/Val loss: 0.616755\n",
      "Epoch: 003 / 010 | Batch 012 / 018 | Train/Val loss: 0.615765\n",
      "Epoch: 003 / 010 | Batch 013 / 018 | Train/Val loss: 0.600959\n",
      "Epoch: 003 / 010 | Batch 014 / 018 | Train/Val loss: 0.587413\n",
      "Epoch: 003 / 010 | Batch 015 / 018 | Train/Val loss: 0.601205\n",
      "Epoch: 003 / 010 | Batch 016 / 018 | Train/Val loss: 0.601360\n",
      "Epoch: 003 / 010 | Batch 017 / 018 | Train/Val loss: 0.582367\n",
      "Train accuracy: 0.897033154964447 | Val accuracy: 0.875\n",
      "Epoch: 004 / 010 | Batch 000 / 018 | Train/Val loss: 0.615639\n",
      "Epoch: 004 / 010 | Batch 001 / 018 | Train/Val loss: 0.599418\n",
      "Epoch: 004 / 010 | Batch 002 / 018 | Train/Val loss: 0.567089\n",
      "Epoch: 004 / 010 | Batch 003 / 018 | Train/Val loss: 0.587052\n",
      "Epoch: 004 / 010 | Batch 004 / 018 | Train/Val loss: 0.601783\n",
      "Epoch: 004 / 010 | Batch 005 / 018 | Train/Val loss: 0.564457\n",
      "Epoch: 004 / 010 | Batch 006 / 018 | Train/Val loss: 0.577422\n",
      "Epoch: 004 / 010 | Batch 007 / 018 | Train/Val loss: 0.580011\n",
      "Epoch: 004 / 010 | Batch 008 / 018 | Train/Val loss: 0.540458\n",
      "Epoch: 004 / 010 | Batch 009 / 018 | Train/Val loss: 0.559290\n",
      "Epoch: 004 / 010 | Batch 010 / 018 | Train/Val loss: 0.574049\n",
      "Epoch: 004 / 010 | Batch 011 / 018 | Train/Val loss: 0.567390\n",
      "Epoch: 004 / 010 | Batch 012 / 018 | Train/Val loss: 0.554118\n",
      "Epoch: 004 / 010 | Batch 013 / 018 | Train/Val loss: 0.580332\n",
      "Epoch: 004 / 010 | Batch 014 / 018 | Train/Val loss: 0.562876\n",
      "Epoch: 004 / 010 | Batch 015 / 018 | Train/Val loss: 0.562635\n",
      "Epoch: 004 / 010 | Batch 016 / 018 | Train/Val loss: 0.567016\n",
      "Epoch: 004 / 010 | Batch 017 / 018 | Train/Val loss: 0.538418\n",
      "Train accuracy: 0.9249563813209534 | Val accuracy: 0.9375\n",
      "Epoch: 005 / 010 | Batch 000 / 018 | Train/Val loss: 0.550300\n",
      "Epoch: 005 / 010 | Batch 001 / 018 | Train/Val loss: 0.535655\n",
      "Epoch: 005 / 010 | Batch 002 / 018 | Train/Val loss: 0.529105\n",
      "Epoch: 005 / 010 | Batch 003 / 018 | Train/Val loss: 0.518194\n",
      "Epoch: 005 / 010 | Batch 004 / 018 | Train/Val loss: 0.514992\n",
      "Epoch: 005 / 010 | Batch 005 / 018 | Train/Val loss: 0.542798\n",
      "Epoch: 005 / 010 | Batch 006 / 018 | Train/Val loss: 0.554813\n",
      "Epoch: 005 / 010 | Batch 007 / 018 | Train/Val loss: 0.538735\n",
      "Epoch: 005 / 010 | Batch 008 / 018 | Train/Val loss: 0.552906\n",
      "Epoch: 005 / 010 | Batch 009 / 018 | Train/Val loss: 0.508472\n",
      "Epoch: 005 / 010 | Batch 010 / 018 | Train/Val loss: 0.492858\n",
      "Epoch: 005 / 010 | Batch 011 / 018 | Train/Val loss: 0.517906\n",
      "Epoch: 005 / 010 | Batch 012 / 018 | Train/Val loss: 0.500946\n",
      "Epoch: 005 / 010 | Batch 013 / 018 | Train/Val loss: 0.480153\n",
      "Epoch: 005 / 010 | Batch 014 / 018 | Train/Val loss: 0.498837\n",
      "Epoch: 005 / 010 | Batch 015 / 018 | Train/Val loss: 0.502371\n",
      "Epoch: 005 / 010 | Batch 016 / 018 | Train/Val loss: 0.461548\n",
      "Epoch: 005 / 010 | Batch 017 / 018 | Train/Val loss: 0.489287\n",
      "Train accuracy: 0.9249563813209534 | Val accuracy: 0.9375\n",
      "Epoch: 006 / 010 | Batch 000 / 018 | Train/Val loss: 0.442491\n",
      "Epoch: 006 / 010 | Batch 001 / 018 | Train/Val loss: 0.471872\n",
      "Epoch: 006 / 010 | Batch 002 / 018 | Train/Val loss: 0.509074\n",
      "Epoch: 006 / 010 | Batch 003 / 018 | Train/Val loss: 0.457922\n",
      "Epoch: 006 / 010 | Batch 004 / 018 | Train/Val loss: 0.486551\n",
      "Epoch: 006 / 010 | Batch 005 / 018 | Train/Val loss: 0.492146\n",
      "Epoch: 006 / 010 | Batch 006 / 018 | Train/Val loss: 0.467551\n",
      "Epoch: 006 / 010 | Batch 007 / 018 | Train/Val loss: 0.455808\n",
      "Epoch: 006 / 010 | Batch 008 / 018 | Train/Val loss: 0.454101\n",
      "Epoch: 006 / 010 | Batch 009 / 018 | Train/Val loss: 0.434925\n",
      "Epoch: 006 / 010 | Batch 010 / 018 | Train/Val loss: 0.442823\n",
      "Epoch: 006 / 010 | Batch 011 / 018 | Train/Val loss: 0.470518\n",
      "Epoch: 006 / 010 | Batch 012 / 018 | Train/Val loss: 0.447044\n",
      "Epoch: 006 / 010 | Batch 013 / 018 | Train/Val loss: 0.443476\n",
      "Epoch: 006 / 010 | Batch 014 / 018 | Train/Val loss: 0.377822\n",
      "Epoch: 006 / 010 | Batch 015 / 018 | Train/Val loss: 0.431847\n",
      "Epoch: 006 / 010 | Batch 016 / 018 | Train/Val loss: 0.423039\n",
      "Epoch: 006 / 010 | Batch 017 / 018 | Train/Val loss: 0.467488\n",
      "Train accuracy: 0.9476439952850342 | Val accuracy: 0.96875\n",
      "Epoch: 007 / 010 | Batch 000 / 018 | Train/Val loss: 0.421341\n",
      "Epoch: 007 / 010 | Batch 001 / 018 | Train/Val loss: 0.422948\n",
      "Epoch: 007 / 010 | Batch 002 / 018 | Train/Val loss: 0.441207\n",
      "Epoch: 007 / 010 | Batch 003 / 018 | Train/Val loss: 0.406194\n",
      "Epoch: 007 / 010 | Batch 004 / 018 | Train/Val loss: 0.380500\n",
      "Epoch: 007 / 010 | Batch 005 / 018 | Train/Val loss: 0.369338\n",
      "Epoch: 007 / 010 | Batch 006 / 018 | Train/Val loss: 0.362873\n",
      "Epoch: 007 / 010 | Batch 007 / 018 | Train/Val loss: 0.408358\n",
      "Epoch: 007 / 010 | Batch 008 / 018 | Train/Val loss: 0.395088\n",
      "Epoch: 007 / 010 | Batch 009 / 018 | Train/Val loss: 0.384327\n",
      "Epoch: 007 / 010 | Batch 010 / 018 | Train/Val loss: 0.417748\n",
      "Epoch: 007 / 010 | Batch 011 / 018 | Train/Val loss: 0.347408\n",
      "Epoch: 007 / 010 | Batch 012 / 018 | Train/Val loss: 0.410697\n",
      "Epoch: 007 / 010 | Batch 013 / 018 | Train/Val loss: 0.330615\n",
      "Epoch: 007 / 010 | Batch 014 / 018 | Train/Val loss: 0.405914\n",
      "Epoch: 007 / 010 | Batch 015 / 018 | Train/Val loss: 0.331094\n",
      "Epoch: 007 / 010 | Batch 016 / 018 | Train/Val loss: 0.374281\n",
      "Epoch: 007 / 010 | Batch 017 / 018 | Train/Val loss: 0.379570\n",
      "Train accuracy: 0.9668411612510681 | Val accuracy: 0.96875\n",
      "Epoch: 008 / 010 | Batch 000 / 018 | Train/Val loss: 0.371958\n",
      "Epoch: 008 / 010 | Batch 001 / 018 | Train/Val loss: 0.310968\n",
      "Epoch: 008 / 010 | Batch 002 / 018 | Train/Val loss: 0.345649\n",
      "Epoch: 008 / 010 | Batch 003 / 018 | Train/Val loss: 0.341324\n",
      "Epoch: 008 / 010 | Batch 004 / 018 | Train/Val loss: 0.372228\n",
      "Epoch: 008 / 010 | Batch 005 / 018 | Train/Val loss: 0.332387\n",
      "Epoch: 008 / 010 | Batch 006 / 018 | Train/Val loss: 0.364565\n",
      "Epoch: 008 / 010 | Batch 007 / 018 | Train/Val loss: 0.321745\n",
      "Epoch: 008 / 010 | Batch 008 / 018 | Train/Val loss: 0.317720\n",
      "Epoch: 008 / 010 | Batch 009 / 018 | Train/Val loss: 0.335479\n",
      "Epoch: 008 / 010 | Batch 010 / 018 | Train/Val loss: 0.301349\n",
      "Epoch: 008 / 010 | Batch 011 / 018 | Train/Val loss: 0.298301\n",
      "Epoch: 008 / 010 | Batch 012 / 018 | Train/Val loss: 0.337508\n",
      "Epoch: 008 / 010 | Batch 013 / 018 | Train/Val loss: 0.309372\n",
      "Epoch: 008 / 010 | Batch 014 / 018 | Train/Val loss: 0.314339\n",
      "Epoch: 008 / 010 | Batch 015 / 018 | Train/Val loss: 0.313274\n",
      "Epoch: 008 / 010 | Batch 016 / 018 | Train/Val loss: 0.289638\n",
      "Epoch: 008 / 010 | Batch 017 / 018 | Train/Val loss: 0.294707\n",
      "Train accuracy: 0.9825479984283447 | Val accuracy: 0.96875\n",
      "Epoch: 009 / 010 | Batch 000 / 018 | Train/Val loss: 0.336534\n",
      "Epoch: 009 / 010 | Batch 001 / 018 | Train/Val loss: 0.224737\n",
      "Epoch: 009 / 010 | Batch 002 / 018 | Train/Val loss: 0.270494\n",
      "Epoch: 009 / 010 | Batch 003 / 018 | Train/Val loss: 0.310327\n",
      "Epoch: 009 / 010 | Batch 004 / 018 | Train/Val loss: 0.297636\n",
      "Epoch: 009 / 010 | Batch 005 / 018 | Train/Val loss: 0.320290\n",
      "Epoch: 009 / 010 | Batch 006 / 018 | Train/Val loss: 0.279773\n",
      "Epoch: 009 / 010 | Batch 007 / 018 | Train/Val loss: 0.254868\n",
      "Epoch: 009 / 010 | Batch 008 / 018 | Train/Val loss: 0.260669\n",
      "Epoch: 009 / 010 | Batch 009 / 018 | Train/Val loss: 0.231636\n",
      "Epoch: 009 / 010 | Batch 010 / 018 | Train/Val loss: 0.303729\n",
      "Epoch: 009 / 010 | Batch 011 / 018 | Train/Val loss: 0.263212\n",
      "Epoch: 009 / 010 | Batch 012 / 018 | Train/Val loss: 0.316759\n",
      "Epoch: 009 / 010 | Batch 013 / 018 | Train/Val loss: 0.259675\n",
      "Epoch: 009 / 010 | Batch 014 / 018 | Train/Val loss: 0.266349\n",
      "Epoch: 009 / 010 | Batch 015 / 018 | Train/Val loss: 0.275782\n",
      "Epoch: 009 / 010 | Batch 016 / 018 | Train/Val loss: 0.211525\n",
      "Epoch: 009 / 010 | Batch 017 / 018 | Train/Val loss: 0.215122\n",
      "Train accuracy: 0.9877836108207703 | Val accuracy: 0.984375\n",
      "Epoch: 010 / 010 | Batch 000 / 018 | Train/Val loss: 0.242777\n",
      "Epoch: 010 / 010 | Batch 001 / 018 | Train/Val loss: 0.286252\n",
      "Epoch: 010 / 010 | Batch 002 / 018 | Train/Val loss: 0.250516\n",
      "Epoch: 010 / 010 | Batch 003 / 018 | Train/Val loss: 0.209173\n",
      "Epoch: 010 / 010 | Batch 004 / 018 | Train/Val loss: 0.204213\n",
      "Epoch: 010 / 010 | Batch 005 / 018 | Train/Val loss: 0.233581\n",
      "Epoch: 010 / 010 | Batch 006 / 018 | Train/Val loss: 0.243144\n",
      "Epoch: 010 / 010 | Batch 007 / 018 | Train/Val loss: 0.159486\n",
      "Epoch: 010 / 010 | Batch 008 / 018 | Train/Val loss: 0.231165\n",
      "Epoch: 010 / 010 | Batch 009 / 018 | Train/Val loss: 0.248322\n",
      "Epoch: 010 / 010 | Batch 010 / 018 | Train/Val loss: 0.175058\n",
      "Epoch: 010 / 010 | Batch 011 / 018 | Train/Val loss: 0.179188\n",
      "Epoch: 010 / 010 | Batch 012 / 018 | Train/Val loss: 0.274783\n",
      "Epoch: 010 / 010 | Batch 013 / 018 | Train/Val loss: 0.179757\n",
      "Epoch: 010 / 010 | Batch 014 / 018 | Train/Val loss: 0.212006\n",
      "Epoch: 010 / 010 | Batch 015 / 018 | Train/Val loss: 0.252063\n",
      "Epoch: 010 / 010 | Batch 016 / 018 | Train/Val loss: 0.252701\n",
      "Epoch: 010 / 010 | Batch 017 / 018 | Train/Val loss: 0.209264\n",
      "Train accuracy: 0.9877836108207703 | Val accuracy: 0.984375\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model = PyTorchMLP(num_features=2, num_classes=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1:03d} / {num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx:03d} / {len(train_loader):03d}\"\n",
    "              f\" | Train/Val loss: {loss:2f}\")\n",
    "\n",
    "    train_acc = compute_accuracy(model, train_loader)\n",
    "    val_acc = compute_accuracy(model, val_loader)\n",
    "    print(f\"Train accuracy: {train_acc} | Val accuracy: {val_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:06.072184516Z",
     "start_time": "2023-10-14T12:35:05.180811875Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (3.8.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (23.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.1.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (10.0.1)\r\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.26.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (4.43.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/alexa/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade matplotlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:09.208783045Z",
     "start_time": "2023-10-14T12:35:06.064768299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('D', '^', 'x', 's', 'v')\n",
    "    colors = ('C0', 'C1', 'C2', 'C3', 'C4')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    tensor = torch.tensor(np.array([xx1.ravel(), xx2.ravel()]).T).float()\n",
    "    logits = classifier.forward(tensor)\n",
    "    Z = np.argmax(logits.detach().numpy(), axis=1)\n",
    "\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, color=cmap(idx),\n",
    "                    #edgecolor='black',\n",
    "                    marker=markers[idx],\n",
    "                    label=cl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:09.209076381Z",
     "start_time": "2023-10-14T12:35:09.208594795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'C0' is not a valid color value.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplot_decision_regions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 25\u001B[0m, in \u001B[0;36mplot_decision_regions\u001B[0;34m(X, y, classifier, resolution)\u001B[0m\n\u001B[1;32m     22\u001B[0m Z \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(logits\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     24\u001B[0m Z \u001B[38;5;241m=\u001B[39m Z\u001B[38;5;241m.\u001B[39mreshape(xx1\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 25\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontourf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxx2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mZ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlim(xx1\u001B[38;5;241m.\u001B[39mmin(), xx1\u001B[38;5;241m.\u001B[39mmax())\n\u001B[1;32m     27\u001B[0m plt\u001B[38;5;241m.\u001B[39mylim(xx2\u001B[38;5;241m.\u001B[39mmin(), xx2\u001B[38;5;241m.\u001B[39mmax())\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/pyplot.py:2938\u001B[0m, in \u001B[0;36mcontourf\u001B[0;34m(data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2936\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mcontourf)\n\u001B[1;32m   2937\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcontourf\u001B[39m(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m QuadContourSet:\n\u001B[0;32m-> 2938\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontourf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2939\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   2940\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2941\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m __ret\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m   2942\u001B[0m         sci(__ret)\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1462\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1463\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1464\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1465\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1467\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1468\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1469\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/axes/_axes.py:6528\u001B[0m, in \u001B[0;36mAxes.contourf\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   6519\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   6520\u001B[0m \u001B[38;5;124;03mPlot filled contours.\u001B[39;00m\n\u001B[1;32m   6521\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   6525\u001B[0m \u001B[38;5;124;03m%(contour_doc)s\u001B[39;00m\n\u001B[1;32m   6526\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   6527\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfilled\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m-> 6528\u001B[0m contours \u001B[38;5;241m=\u001B[39m \u001B[43mmcontour\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mQuadContourSet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6529\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request_autoscale_view()\n\u001B[1;32m   6530\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m contours\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/contour.py:887\u001B[0m, in \u001B[0;36mContourSet.__init__\u001B[0;34m(self, ax, levels, filled, linewidths, linestyles, hatches, alpha, origin, extent, cmap, colors, norm, vmin, vmax, extend, antialiased, nchunk, locator, transform, negative_linestyles, clip_path, *args, **kwargs)\u001B[0m\n\u001B[1;32m    884\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabelTexts \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    885\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabelCValues \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 887\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_cmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m norm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    889\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_norm(norm)\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cm.py:602\u001B[0m, in \u001B[0;36mScalarMappable.set_cmap\u001B[0;34m(self, cmap)\u001B[0m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcmap \u001B[38;5;241m=\u001B[39m _ensure_cmap(cmap)\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m in_init:\n\u001B[0;32m--> 602\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchanged\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/contour.py:1145\u001B[0m, in \u001B[0;36mContourSet.changed\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchanged\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1144\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1145\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_colors\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Sets cvalues.\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m     \u001B[38;5;66;03m# Force an autoscale immediately because self.to_rgba() calls\u001B[39;00m\n\u001B[1;32m   1147\u001B[0m     \u001B[38;5;66;03m# autoscale_None() internally with the data passed to it,\u001B[39;00m\n\u001B[1;32m   1148\u001B[0m     \u001B[38;5;66;03m# so if vmin/vmax are not set yet, this would override them with\u001B[39;00m\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;66;03m# content from *cvalues* rather than levels like we want\u001B[39;00m\n\u001B[1;32m   1150\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm\u001B[38;5;241m.\u001B[39mautoscale_None(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlevels)\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/contour.py:1302\u001B[0m, in \u001B[0;36mContourSet._process_colors\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1301\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcvalues \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers\n\u001B[0;32m-> 1302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautoscale_None\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlevels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1303\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_array(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcvalues)\n\u001B[1;32m   1304\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_scalarmappable()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1408\u001B[0m, in \u001B[0;36mNormalize.autoscale_None\u001B[0;34m(self, A)\u001B[0m\n\u001B[1;32m   1405\u001B[0m         A \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m   1407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvmin \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m A\u001B[38;5;241m.\u001B[39msize:\n\u001B[0;32m-> 1408\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvmin\u001B[49m \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mmin()\n\u001B[1;32m   1409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvmax \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m A\u001B[38;5;241m.\u001B[39msize:\n\u001B[1;32m   1410\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvmax \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mmax()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1264\u001B[0m, in \u001B[0;36mNormalize.vmin\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vmin:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vmin \u001B[38;5;241m=\u001B[39m value\n\u001B[0;32m-> 1264\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_changed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1292\u001B[0m, in \u001B[0;36mNormalize._changed\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1287\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_changed\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1288\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1289\u001B[0m \u001B[38;5;124;03m    Call this whenever the norm is changed to notify all the\u001B[39;00m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;124;03m    callback listeners to the 'changed' signal.\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1292\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchanged\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cbook.py:303\u001B[0m, in \u001B[0;36mCallbackRegistry.process\u001B[0;34m(self, s, *args, **kwargs)\u001B[0m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 303\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexception_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cbook.py:87\u001B[0m, in \u001B[0;36m_exception_printer\u001B[0;34m(exc)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_exception_printer\u001B[39m(exc):\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _get_running_interactive_framework() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheadless\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]:\n\u001B[0;32m---> 87\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m         traceback\u001B[38;5;241m.\u001B[39mprint_exc()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cbook.py:298\u001B[0m, in \u001B[0;36mCallbackRegistry.process\u001B[0;34m(self, s, *args, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 298\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;66;03m# this does not capture KeyboardInterrupt, SystemExit,\u001B[39;00m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;66;03m# and GeneratorExit\u001B[39;00m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/contour.py:1150\u001B[0m, in \u001B[0;36mContourSet.changed\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_colors()  \u001B[38;5;66;03m# Sets cvalues.\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;66;03m# Force an autoscale immediately because self.to_rgba() calls\u001B[39;00m\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;66;03m# autoscale_None() internally with the data passed to it,\u001B[39;00m\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;66;03m# so if vmin/vmax are not set yet, this would override them with\u001B[39;00m\n\u001B[1;32m   1149\u001B[0m \u001B[38;5;66;03m# content from *cvalues* rather than levels like we want\u001B[39;00m\n\u001B[0;32m-> 1150\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautoscale_None\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlevels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_array(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcvalues)\n\u001B[1;32m   1152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_scalarmappable()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1410\u001B[0m, in \u001B[0;36mNormalize.autoscale_None\u001B[0;34m(self, A)\u001B[0m\n\u001B[1;32m   1408\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvmin \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mmin()\n\u001B[1;32m   1409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvmax \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m A\u001B[38;5;241m.\u001B[39msize:\n\u001B[0;32m-> 1410\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvmax\u001B[49m \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mmax()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1275\u001B[0m, in \u001B[0;36mNormalize.vmax\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m   1273\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vmax:\n\u001B[1;32m   1274\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vmax \u001B[38;5;241m=\u001B[39m value\n\u001B[0;32m-> 1275\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_changed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1292\u001B[0m, in \u001B[0;36mNormalize._changed\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1287\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_changed\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1288\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1289\u001B[0m \u001B[38;5;124;03m    Call this whenever the norm is changed to notify all the\u001B[39;00m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;124;03m    callback listeners to the 'changed' signal.\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1292\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchanged\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cbook.py:303\u001B[0m, in \u001B[0;36mCallbackRegistry.process\u001B[0;34m(self, s, *args, **kwargs)\u001B[0m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 303\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexception_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cbook.py:87\u001B[0m, in \u001B[0;36m_exception_printer\u001B[0;34m(exc)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_exception_printer\u001B[39m(exc):\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _get_running_interactive_framework() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheadless\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]:\n\u001B[0;32m---> 87\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m         traceback\u001B[38;5;241m.\u001B[39mprint_exc()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cbook.py:298\u001B[0m, in \u001B[0;36mCallbackRegistry.process\u001B[0;34m(self, s, *args, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 298\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;66;03m# this does not capture KeyboardInterrupt, SystemExit,\u001B[39;00m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;66;03m# and GeneratorExit\u001B[39;00m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/contour.py:1152\u001B[0m, in \u001B[0;36mContourSet.changed\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm\u001B[38;5;241m.\u001B[39mautoscale_None(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlevels)\n\u001B[1;32m   1151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_array(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcvalues)\n\u001B[0;32m-> 1152\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_scalarmappable\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1153\u001B[0m alphas \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbroadcast_to(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_alpha(), \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcvalues))\n\u001B[1;32m   1154\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m label, cv, alpha \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabelTexts, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabelCValues, alphas):\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/collections.py:920\u001B[0m, in \u001B[0;36mCollection.update_scalarmappable\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    918\u001B[0m         \u001B[38;5;66;03m# pcolormesh, scatter, maybe others flatten their _A\u001B[39;00m\n\u001B[1;32m    919\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m--> 920\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mapped_colors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_rgba\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_A\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_alpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_face_is_mapped:\n\u001B[1;32m    923\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_facecolors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mapped_colors\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/cm.py:509\u001B[0m, in \u001B[0;36mScalarMappable.to_rgba\u001B[0;34m(self, x, alpha, bytes, norm)\u001B[0m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m norm:\n\u001B[1;32m    508\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(x)\n\u001B[0;32m--> 509\u001B[0m rgba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mbytes\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mbytes\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m rgba\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:725\u001B[0m, in \u001B[0;36mColormap.__call__\u001B[0;34m(self, X, alpha, bytes)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;124;03m----------\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    722\u001B[0m \u001B[38;5;124;03mRGBA values with a shape of ``X.shape + (4, )``.\u001B[39;00m\n\u001B[1;32m    723\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_isinit:\n\u001B[0;32m--> 725\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    727\u001B[0m xa \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    728\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m xa\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39misnative:\n\u001B[1;32m    729\u001B[0m     \u001B[38;5;66;03m# Native byteorder is faster.\u001B[39;00m\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:1175\u001B[0m, in \u001B[0;36mListedColormap._init\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_init\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1174\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lut \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m), \u001B[38;5;28mfloat\u001B[39m)\n\u001B[0;32m-> 1175\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lut[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mto_rgba_array\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1176\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_isinit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1177\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_extremes()\n",
      "File \u001B[0;32m~/codingTime/dl_lightning_ai_course/venv/lib/python3.10/site-packages/matplotlib/colors.py:489\u001B[0m, in \u001B[0;36mto_rgba_array\u001B[0;34m(c, alpha)\u001B[0m\n\u001B[1;32m    487\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(c, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 489\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m is not a valid color value.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    491\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(c) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    492\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m4\u001B[39m), \u001B[38;5;28mfloat\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: 'C0' is not a valid color value."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_regions(X_train, y_train, classifier=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T12:35:10.914893823Z",
     "start_time": "2023-10-14T12:35:09.208987418Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
