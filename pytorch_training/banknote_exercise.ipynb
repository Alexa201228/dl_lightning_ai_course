{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:21:28.611116200Z",
     "start_time": "2023-10-10T18:21:26.889263500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: torch in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from matplotlib) (6.1.0)\n",
      "Requirement already satisfied: filelock in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\programming train\\dl_lightning_ai_course\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import  torch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:22:34.544121900Z",
     "start_time": "2023-10-10T18:22:19.083685100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download and inspect data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         0       1       2        3  4\n0  3.62160  8.6661 -2.8073 -0.44699  0\n1  4.54590  8.1674 -2.4586 -1.46210  0\n2  3.86600 -2.6383  1.9242  0.10645  0\n3  3.45660  9.5228 -4.0112 -3.59440  0\n4  0.32924 -4.4552  4.5718 -0.98880  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.62160</td>\n      <td>8.6661</td>\n      <td>-2.8073</td>\n      <td>-0.44699</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.54590</td>\n      <td>8.1674</td>\n      <td>-2.4586</td>\n      <td>-1.46210</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.86600</td>\n      <td>-2.6383</td>\n      <td>1.9242</td>\n      <td>0.10645</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.45660</td>\n      <td>9.5228</td>\n      <td>-4.0112</td>\n      <td>-3.59440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.32924</td>\n      <td>-4.4552</td>\n      <td>4.5718</td>\n      <td>-0.98880</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_banknote_authentication.txt\", header=None)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:22:34.637534700Z",
     "start_time": "2023-10-10T18:22:34.545122100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_features = df[[0, 1, 2, 3]].values\n",
    "y_target = df[4].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:24:33.948256600Z",
     "start_time": "2023-10-10T18:24:33.927226600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(1372, 4)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:24:35.564036900Z",
     "start_time": "2023-10-10T18:24:35.515348400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([762, 610], dtype=int64)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.bincount(y_target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:24:55.235388700Z",
     "start_time": "2023-10-10T18:24:55.221391800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create custom Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class BanknoteDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        self._features = torch.tensor(X, dtype=torch.float32)\n",
    "        self._labels = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self._features[index]\n",
    "        y = self._labels[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._labels.shape[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:35:29.304045300Z",
     "start_time": "2023-10-10T18:35:29.292046900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1097"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(X_features.shape[0] * 0.8)\n",
    "train_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:31:44.891935500Z",
     "start_time": "2023-10-10T18:31:44.844550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "275"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = X_features.shape[0] - train_size\n",
    "test_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:32:14.641530300Z",
     "start_time": "2023-10-10T18:32:14.626274500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data to train and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dataset = BanknoteDataset(X_features, y_target)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:35:34.712179600Z",
     "start_time": "2023-10-10T18:35:34.290668900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing Logistic Regression Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "\n",
    "        super().__init__()\n",
    "        self._linear = torch.nn.Linear(num_features, 1)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self._linear(X)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:40:54.564601300Z",
     "start_time": "2023-10-10T18:40:54.554474500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probas = model(features)\n",
    "\n",
    "        pred = torch.where(probas > 0.5, 1, 0)\n",
    "        lab = class_labels.view(pred.shape).to(pred.dtype)\n",
    "\n",
    "        compare = lab == pred\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:42:58.000780400Z",
     "start_time": "2023-10-10T18:42:57.985301700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs_stop = 30\n",
    "learning_rate_stop = 3\n",
    "\n",
    "def find_optimal_hyperparameters():\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    model = LogisticRegressionModel(num_features=4)\n",
    "\n",
    "    stop_learning = False\n",
    "    best_lr = 0\n",
    "    best_num_epochs = 0\n",
    "    for epochs_count in range(1, num_epochs_stop):\n",
    "        if stop_learning:\n",
    "            break\n",
    "        num_epochs = epochs_count\n",
    "        curr_lr = 0.1\n",
    "        while curr_lr < learning_rate_stop:\n",
    "            if stop_learning:\n",
    "                break\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=curr_lr)\n",
    "            for epoch in range(num_epochs):\n",
    "                if stop_learning:\n",
    "                    break\n",
    "                model = model.train()\n",
    "                for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "\n",
    "                    probas = model(features)\n",
    "\n",
    "                    loss = F.binary_cross_entropy(probas, class_labels.view(probas.shape))\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    ### LOGGING\n",
    "                    if not batch_idx % 20: # log every 20th batch\n",
    "                        print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}'\n",
    "                               f' | Batch {batch_idx:03d}/{len(train_loader):03d}'\n",
    "                               f' | Loss: {loss:.2f}')\n",
    "                    train_acc = compute_accuracy(model, train_loader)\n",
    "                    val_acc = compute_accuracy(model, val_loader)\n",
    "                    if train_acc * 100 > 98 and val_acc * 100 > 98:\n",
    "                        best_lr = curr_lr\n",
    "                        best_num_epochs = epochs_count\n",
    "                        break\n",
    "\n",
    "            curr_lr += 0.1\n",
    "\n",
    "        return {\"best_lr\": best_lr, \"best_num_epochs\": best_num_epochs, \"model\": model}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T19:03:28.732676500Z",
     "start_time": "2023-10-10T19:03:28.721336200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/001 | Batch 000/110 | Loss: 1.30\n",
      "Epoch: 001/001 | Batch 020/110 | Loss: 0.17\n",
      "Epoch: 001/001 | Batch 040/110 | Loss: 0.29\n",
      "Epoch: 001/001 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 001/001 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 001/001 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 001/001 | Batch 020/110 | Loss: 0.23\n",
      "Epoch: 001/001 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 001/001 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.07\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.08\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.18\n",
      "Epoch: 001/001 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 001/001 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 040/110 | Loss: 0.59\n",
      "Epoch: 001/001 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 000/110 | Loss: 0.58\n",
      "Epoch: 001/001 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 001/001 | Batch 040/110 | Loss: 0.26\n",
      "Epoch: 001/001 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 001/001 | Batch 080/110 | Loss: 0.92\n"
     ]
    }
   ],
   "source": [
    "res = find_optimal_hyperparameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T19:03:46.327510300Z",
     "start_time": "2023-10-10T19:03:32.189916200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_lr': 2.9000000000000012, 'best_num_epochs': 1, 'model': LogisticRegressionModel(\n",
      "  (_linear): Linear(in_features=4, out_features=1, bias=True)\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T19:03:46.345508300Z",
     "start_time": "2023-10-10T19:03:46.329524400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.91%\n"
     ]
    }
   ],
   "source": [
    "val_acc = compute_accuracy(res[\"model\"], val_loader)\n",
    "print(f\"Accuracy: {val_acc * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T19:04:34.237503200Z",
     "start_time": "2023-10-10T19:04:34.226506200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
